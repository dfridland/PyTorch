{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4AvB7MFuG/AkXpwWRblGc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dfridland/PyTorch/blob/HW3/PyTorchHW03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "rdOHo9Dp9Kvf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime as dt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import r2_score\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import stats\n",
        "import warnings\n",
        "import math\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "\n",
        "data = fetch_california_housing()"
      ],
      "metadata": {
        "id": "JV9eoG_v9bUm"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyDataset(torch.utils.data.Dataset):\n",
        "   \n",
        "    def __init__(self, init_dataset, init_target, transform=None):\n",
        "        self._base_dataset = torch.from_numpy(init_dataset).type(torch.float)\n",
        "        self._base_targets = torch.from_numpy(init_target).type(torch.float)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._base_dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        features = self._base_dataset[idx]\n",
        "        target = self._base_targets[idx]\n",
        "\n",
        "        if self.transform is not None:\n",
        "            features = self.transform(features)\n",
        "      \n",
        "        return features, target\n",
        "\n"
      ],
      "metadata": {
        "id": "z-sIq6FM_sQk"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim, activation=\"relu\"):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(input_dim, output_dim)\n",
        "        self.activation = activation\n",
        "\n",
        "  def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        if self.activation == \"relu\":\n",
        "            return F.relu(x)\n",
        "        if self.activation == \"leaky_relu\":\n",
        "            return F.leaky_relu(x)\n",
        "        if self.activation == \"sigmoid\":\n",
        "            return F.sigmoid(x)\n",
        "        raise RuntimeError\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.fc1 = Perceptron(input_dim, hidden_dim, 'leaky_relu')\n",
        "        self.bn = nn.BatchNorm1d(hidden_dim)\n",
        "        self.dp = nn.Dropout(0.25)\n",
        "        self.fc2 = Perceptron(hidden_dim, 1, \"sigmoid\")\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.dp(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "     "
      ],
      "metadata": {
        "id": "aFGtLzl9MpLz"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data['data'], data['target'], test_size = 0.25, random_state = 13)\n"
      ],
      "metadata": {
        "id": "xUDKVZ7h6lFe"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = MyDataset(X_train, y_train)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=150, shuffle=False)"
      ],
      "metadata": {
        "id": "fMIC8tzQ6qLi"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = MyDataset(X_test, y_test)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=10, shuffle=False)"
      ],
      "metadata": {
        "id": "5TooRLf36ghB"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class FeedForward(nn.Module):\n",
        "#     def __init__(self, input_dim, hidden_dim):\n",
        "#         super(FeedForward, self).__init__()\n",
        "#         self.bn1 = nn.BatchNorm1d(input_dim)\n",
        "#         self.fc1 = Perceptron(input_dim, hidden_dim)\n",
        "#         self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
        "#         self.dp = nn.Dropout(0.25)\n",
        "#         self.fc2 = Perceptron(hidden_dim, 1, \"sigmoid\")\n",
        "        \n",
        "#     def forward(self, x):\n",
        "#         x = self.bn1(x)\n",
        "#         x = self.fc1(x)\n",
        "#         x = self.dp(x)\n",
        "#         x = self.fc2(x)\n",
        "#         return x.view(-1)\n"
      ],
      "metadata": {
        "id": "x71N01WDCDNT"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = FeedForward(8, 50)\n",
        "net\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ww2xljYdDycg",
        "outputId": "28bab67e-1a59-49c2-a600-4487377e24d7"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FeedForward(\n",
              "  (fc1): Perceptron(\n",
              "    (fc): Linear(in_features=8, out_features=50, bias=True)\n",
              "  )\n",
              "  (bn): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (dp): Dropout(p=0.25, inplace=False)\n",
              "  (fc2): Perceptron(\n",
              "    (fc): Linear(in_features=50, out_features=1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#optimizer = torch.optim.SGD(net.parameters(), lr=0.001)\n",
        "# optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "optimizer = torch.optim.RMSprop(net.parameters(), lr=0.001)\n",
        "\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "kWxBCdQJN7ka"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    net.cuda()"
      ],
      "metadata": {
        "id": "-NYF1OnKOEbh"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):  \n",
        "    running_loss, running_items, r2 = 0.0, 0.0, 0.0\n",
        "\n",
        "    for i, data in enumerate(train_loader):\n",
        "        fets, target = data[0], data[1]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(fets)\n",
        "        loss = criterion(outputs, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        running_items += len(target)\n",
        "\n",
        "        predict = outputs.data.numpy()\n",
        "        train_target = target.view(target.shape[0], 1).numpy()\n",
        "        r2 += r2_score(train_target, predict)\n",
        "        \n",
        "        if i % 30 == 0:\n",
        "            net.eval()\n",
        "\n",
        "            data = list(test_loader)[0]\n",
        "\n",
        "            test_outputs = net(data[0])\n",
        "            test_predict = test_outputs.data.numpy()\n",
        "            test_target = data[1].view(data[1].shape[0], 1)\n",
        "            test_r2 = r2_score(test_target, test_predict)\n",
        "\n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}]. ' \\\n",
        "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                  f'Loss: {running_loss / running_items:.3f}. ' \\\n",
        "                  f'r2: {r2:.3f}. ' \\\n",
        "                  f'Test r2: {test_r2:.3f}')\n",
        "\n",
        "            running_loss, running_items, r2 = 0.0, 0.0, 0.0\n",
        "\n",
        "            net.train()\n",
        "        \n",
        "print(\"Training  is done!\")\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUGAGd456GfN",
        "outputId": "5d9d9669-290d-465c-96c1-b7e558dbf6cd"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10]. Step [1/104]. Loss: 0.028. r2: -1.794. Test r2: -2.030\n",
            "Epoch [1/10]. Step [31/104]. Loss: 0.024. r2: -54.051. Test r2: -2.475\n",
            "Epoch [1/10]. Step [61/104]. Loss: 0.024. r2: -49.329. Test r2: -2.151\n",
            "Epoch [1/10]. Step [91/104]. Loss: 0.022. r2: -45.697. Test r2: -1.781\n",
            "Epoch [2/10]. Step [1/104]. Loss: 0.024. r2: -1.407. Test r2: -1.610\n",
            "Epoch [2/10]. Step [31/104]. Loss: 0.020. r2: -39.585. Test r2: -1.342\n",
            "Epoch [2/10]. Step [61/104]. Loss: 0.019. r2: -34.366. Test r2: -1.148\n",
            "Epoch [2/10]. Step [91/104]. Loss: 0.018. r2: -31.648. Test r2: -1.057\n",
            "Epoch [3/10]. Step [1/104]. Loss: 0.020. r2: -1.006. Test r2: -1.025\n",
            "Epoch [3/10]. Step [31/104]. Loss: 0.017. r2: -29.773. Test r2: -0.979\n",
            "Epoch [3/10]. Step [61/104]. Loss: 0.017. r2: -27.901. Test r2: -0.955\n",
            "Epoch [3/10]. Step [91/104]. Loss: 0.017. r2: -27.477. Test r2: -0.944\n",
            "Epoch [4/10]. Step [1/104]. Loss: 0.019. r2: -0.931. Test r2: -0.933\n",
            "Epoch [4/10]. Step [31/104]. Loss: 0.016. r2: -27.647. Test r2: -0.926\n",
            "Epoch [4/10]. Step [61/104]. Loss: 0.017. r2: -26.626. Test r2: -0.924\n",
            "Epoch [4/10]. Step [91/104]. Loss: 0.016. r2: -26.601. Test r2: -0.918\n",
            "Epoch [5/10]. Step [1/104]. Loss: 0.019. r2: -0.914. Test r2: -0.916\n",
            "Epoch [5/10]. Step [31/104]. Loss: 0.016. r2: -27.057. Test r2: -0.914\n",
            "Epoch [5/10]. Step [61/104]. Loss: 0.017. r2: -26.284. Test r2: -0.912\n",
            "Epoch [5/10]. Step [91/104]. Loss: 0.016. r2: -26.219. Test r2: -0.912\n",
            "Epoch [6/10]. Step [1/104]. Loss: 0.019. r2: -0.907. Test r2: -0.910\n",
            "Epoch [6/10]. Step [31/104]. Loss: 0.016. r2: -26.781. Test r2: -0.910\n",
            "Epoch [6/10]. Step [61/104]. Loss: 0.017. r2: -26.049. Test r2: -0.908\n",
            "Epoch [6/10]. Step [91/104]. Loss: 0.016. r2: -26.069. Test r2: -0.908\n",
            "Epoch [7/10]. Step [1/104]. Loss: 0.019. r2: -0.902. Test r2: -0.907\n",
            "Epoch [7/10]. Step [31/104]. Loss: 0.016. r2: -26.691. Test r2: -0.908\n",
            "Epoch [7/10]. Step [61/104]. Loss: 0.017. r2: -25.920. Test r2: -0.906\n",
            "Epoch [7/10]. Step [91/104]. Loss: 0.016. r2: -25.984. Test r2: -0.906\n",
            "Epoch [8/10]. Step [1/104]. Loss: 0.019. r2: -0.900. Test r2: -0.906\n",
            "Epoch [8/10]. Step [31/104]. Loss: 0.016. r2: -26.604. Test r2: -0.906\n",
            "Epoch [8/10]. Step [61/104]. Loss: 0.017. r2: -25.895. Test r2: -0.907\n",
            "Epoch [8/10]. Step [91/104]. Loss: 0.016. r2: -25.998. Test r2: -0.905\n",
            "Epoch [9/10]. Step [1/104]. Loss: 0.019. r2: -0.898. Test r2: -0.905\n",
            "Epoch [9/10]. Step [31/104]. Loss: 0.016. r2: -26.554. Test r2: -0.905\n",
            "Epoch [9/10]. Step [61/104]. Loss: 0.017. r2: -25.836. Test r2: -0.904\n",
            "Epoch [9/10]. Step [91/104]. Loss: 0.016. r2: -25.910. Test r2: -0.904\n",
            "Epoch [10/10]. Step [1/104]. Loss: 0.019. r2: -0.898. Test r2: -0.904\n",
            "Epoch [10/10]. Step [31/104]. Loss: 0.016. r2: -26.525. Test r2: -0.904\n",
            "Epoch [10/10]. Step [61/104]. Loss: 0.017. r2: -25.808. Test r2: -0.904\n",
            "Epoch [10/10]. Step [91/104]. Loss: 0.016. r2: -25.884. Test r2: -0.904\n",
            "Training  is done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adam and RMS are optimizators of choice. "
      ],
      "metadata": {
        "id": "KWW5XxNH-e_U"
      },
      "execution_count": 85,
      "outputs": []
    }
  ]
}